---
title: Notes on ðŸ“•<i>Data Structures & Abstractions with Java</i> by Frank M. Carrano
description: "In-progress, incomplete"
hidden: true
author: Daniel Dantas
---

I use these notes to track thoughts I had, and things I found interesting, while reading _Data Structures & Abstractions with Java_

The notes are still in progress as I have not yet finished reading the book

## Introduction
- Abstract data types and data structures are contrasted in Wikipedia [as](https://en.wikipedia.org/wiki/Abstract_data_type) as "_an abstract data type (ADT) is a mathematical model for data types, defined by its behavior (semantics) from the point of view of a user of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This mathematical model contrasts with data structures, which are concrete representations of data, and are the point of view of an implementer, not a user_" and [as](https://en.wikipedia.org/wiki/Data_structure) "_Data structures serve as the basis for abstract data types (ADT). The ADT defines the logical form of the data type. The data structure implements the physical form of the data type_"

## 1. Bags
- A data type is defined in [Wikipedia](https://en.wikipedia.org/wiki/Data_type) as "_a collection or grouping of data values, usually specified by a set of possible values, a set of allowed operations on these values, and/or a representation of these values as machine types_"
- According to the Java [documentation](https://docs.oracle.com/javase/tutorial/java/javaOO/methods.html), "_You cannot declare more than one method with the same name and the same number and type of arguments, because the compiler cannot tell them apart_"
- The book recommends writing code that uses and tests the interface before attempting to implement the interface
- Encapsulation is definied in [Wikipedia](https://en.wikipedia.org/wiki/Encapsulation_(computer_programming)) as "_the bundling of data with the mechanisms or methods that operate on the data_"
- The book recommends designing an abstract data type by only worrying about how the user will use it, and not about the implementation. There can be a tendency to let the underlying algorithms influence the interface, but this recommendation would resist that

## 2. Bag Implementations That Uses Arrays
- The `final` keyword in Java on a field ensures that the field cannot be changed after its initial assignment (though the contents of the field can change)
- There are three ways (at least) to shallow copy arrays: [Object.clone](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/lang/Object.html#clone()), [System.arraycopy](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/lang/System.html#arraycopy(java.lang.Object,int,java.lang.Object,int,int)), and [Arrays.copyOf](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Arrays.html#copyOf(T%5B%5D,int)). The latter two methods are useful for resizing arrays
- This book has a style where they set a result in various branches and then return the result at the end of the method when all the branches have come back together, instead of returning early when and if necessary. I find the latter style easier to understand
- The use of `.equals` as an equivalence relation has issues with `null`s
- The reason doubling is used in array resizing is it lets the `add`s have an amortized O(1) running time (each `add` banks a constant amount of time for copying during a resize)

## 3. A Bag Implementation That Links Data
- Inner / nested class is defined in [Wikipedia](https://en.wikipedia.org/wiki/Inner_class) as "_a class declared entirely within the body of another class or interface_"
- The book defines a nontraditional list remove method: it replaces the to-be-removed node's data with the first node's data, then pops the first node
- The book defines a list clear method as continually popping from the list, with O(n) running time. But it seems simpler to set the head reference to null and let the garbage collector do the work
- The Java [documentation](https://docs.oracle.com/javase/tutorial/java/javaOO/accesscontrol.html) states "_If a class has no modifier (the default, also known as package-private), it is visible only within its own package_", which the book points out is an alternative to inner classes
- The Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/doc-files/coll-reference.html) describes List implementations as follows: "_ArrayList - Resizable array implementation of the List interface (an unsynchronized Vector). The best all-around implementation of the List interface. LinkedList - Doubly-linked list implementation of the List interface. Provides better performance than the ArrayList implementation if elements are frequently inserted or deleted within the list_"

## 4. The Efficiency of Algorithms
- Complexity is defined in [Wikipedia](https://en.wikipedia.org/wiki/Computational_complexity) as "_amount of resources required to run it. Particular focus is given to computation time (generally measured by the number of needed elementary operations) and memory storage requirements_"
- Analysis of algorithms is defined in [Wikipedia](https://en.wikipedia.org/wiki/Analysis_of_algorithms) as "_the process of finding the computational complexity of algorithms_"
- Big O notation is defined by [Wikipedia](https://en.wikipedia.org/wiki/Big_O_notation) as "_mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity_"

## 5. Stacks
- The book points out that pushing items onto, and then popping all items from a stack, reverses the order
- The book points out that infix operators require precedence and parentheses to process as expected, but prefix and postfix bake the precedence into the expression `1+2*4 vs. `1 2 4 * +`
- Shunting yard algorithm is defined in [Wikipedia](https://en.wikipedia.org/wiki/Shunting_yard_algorithm) as "_method for parsing arithmetical or logical expressions, or a combination of both, specified in infix notation... The input is processed one symbol at a time: if a variable or number is found, it is copied directly to the output... If the symbol is an operator, it is pushed onto the operator stack... If the operator's precedence is lower than that of the operators at the top of the stack or the precedences are equal and the operator is left associative, then that operator is popped off the stack and added to the output... Finally, any remaining operators are popped off the stack and added to the output_"
- The book explains that instead of outputting the result of the shunting yard algorithm as a postfix expression, you can evaluate it on the fly by using an operand stack
- Frame is defined in the Java [documentation](https://docs.oracle.com/javase/specs/jvms/se24/html/jvms-2.html#jvms-2.6) as "_used to store data and partial results, as well as to perform dynamic linking, return values for methods, and dispatch exceptions_"
- Java Virtual Machine stack is defined in the Java [documentation](https://docs.oracle.com/javase/specs/jvms/se24/html/jvms-2.html#jvms-2.5.2) as "_stores frames... it holds local variables and partial results, and plays a part in method invocation and return. Because the Java Virtual Machine stack is never manipulated directly except to push and pop frames, frames may be heap allocated. The memory for a Java Virtual Machine stack does not need to be contiguous_"
- `java.util.ArrayDeque<E>` is defined by the Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/doc-files/coll-reference.html) as "_efficient, resizable array implementation of the `Deque` interface_"

## 6. Stack Implementations
- Stacks using linked lists are described in [Wikipedia](https://en.wikipedia.org/wiki/Stack_(abstract_data_type)#Linked_list) as "_Another option for implementing stacks is to use a singly linked list. A stack is then a pointer to the "head" of the list, with perhaps a counter to keep track of the size of the list...Pushing and popping items happens at the head of the list_"
- Stacks using arrays are described in [Wikipedia](https://en.wikipedia.org/wiki/Stack_(abstract_data_type)#Array) as "_The program must keep track of the size (length) of the stack, using a variable top that records the number of items pushed so far, therefore pointing to the place in the array where the next element is to be inserted.... The size of the stack is simply the size of the dynamic array, which is a very efficient implementation of a stack since adding items to or removing items from the end of a dynamic array requires amortized O(1) time_"
- `java.util.Arrays.copyof` is described in the Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Arrays.html#copyOf(T%5B%5D,int)) as "_Copies the specified array, truncating or padding with nulls (if necessary) so the copy has the specified length_"
- The book makes sure to set the stack array to null upon pop or clear, so that garbage collection can kick in
- The book uses a `Vector`, but the current version is `java.util.ArrayList` which is described in the Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/ArrayList.html) as "_Resizable-array implementation of the List interface.... The `size`, `isEmpty`, `get`, `set`, `getFirst`, `getLast`, `removeLast`, `iterator`, `listIterator`, and `reversed` operations run in constant time. The `add`, and `addLast` operations runs in amortized constant time, that is, adding n elements requires O(n) time. All of the other operations_ \[e.g. `addFirst`\] _run in linear time (roughly speaking). The constant factor is low compared to that for the LinkedList implementation_"
- The book advises that a stack should not inherit from a vector because a stack has-a vector, not is-a vector
- Is-a is defined in Wikipedia as "_subsumptive relationship between abstractions (e.g., types, classes), wherein one class A is a subclass of another class B (and so B is a superclass of A). In other words, type A is a subtype of type B when A's specification implies B's specification. That is, any object (or class) that satisfies A's specification also satisfies B's specification, because B's specification is weaker_"
- Has-a is defined in Wikipedia as "_composition relationship where one object (often called the constituted object, or part/constituent/member object) 'belongs to' (is part or member of) another object (called the composite type), and behaves according to the rules of ownership. In simple words, has-a relationship in an object is called a member field of an object_"

## 7. Recursion
- Recursion is defined in [Wikipedia](https://en.wikipedia.org/wiki/Recursion_(computer_science)) as "_method of solving a computational problem where the solution depends on solutions to smaller instances of the same problem.... Repeatedly calling a function from within itself may cause the call stack to have a size equal to the sum of the input sizes of all involved calls. It follows that, for problems that can be solved easily by iteration, recursion is generally less efficient, and, for certain problems, algorithmic or compiler-optimization techniques such as tail call optimization may improve computational performance over a naive recursive implementation.... A recursive function definition has one or more base cases, meaning input(s) for which the function produces a result trivially (without recurring), and one or more recursive cases, meaning input(s) for which the program recurs (calls itself)... Recursion and iteration are equally expressive: recursion can be replaced by iteration with an explicit call stack, while iteration can be replaced with tail recursion_"
- Frame is defined in the Java [documentation](https://docs.oracle.com/javase/specs/jvms/se11/html/jvms-2.html#jvms-2.6) as "_used to store data and partial results, as well as to perform dynamic linking, return values for methods, and dispatch exceptions. A new frame is created each time a method is invoked. A frame is destroyed when its method invocation completes, whether that completion is normal or abrupt (it throws an uncaught exception). Frames are allocated from the Java Virtual Machine stack..._"
- The book points out that some problems, like traversing a linked list in reverse order, are expressed more naturally with recursion than iteration
- The book points out that recursive methods are often private because their signature often reveals information about the implementation of the class. As such, they are called by more general public method 
- Recurrence relation is defined in [Wikipedia](https://en.wikipedia.org/wiki/Recurrence_relation) as "_equation according to which the nth term of a sequence of numbers is equal to some combination of the previous terms_"
- Proof by induction is defined in [Wikipedia](https://en.wikipedia.org/wiki/Mathematical_induction) as "_consists of two cases. The first, the base case, proves the statement for n=0 without assuming any knowledge of other cases. The second case, the induction step, proves that if the statement holds for any given case n=k, then it must also hold for the next case n=k+1.... The method can be extended to prove statements about more general well-founded structures, such as trees_"
   Tail call is defined in [Wikipedia](https://en.wikipedia.org/wiki/Tail_call) as "_a subroutine call performed as the final action of a procedure. If the target of a tail is the same subroutine, the subroutine is said to be tail recursive.... Tail calls can be implemented without adding a new stack frame to the call stack.... Tail recursion can be related to the while statement, an explicit iteration_"
- The book points out that Java does not implement tail call optimization. I believe one reason is that the Java security mechanism does stack inspection
- The book presents a partially iterative version of towers of hanoi, but it's hard to understand so it's clear why the recursive version is preferred
- Indirect recursion is defined in [Wikipedia](https://en.wikipedia.org/wiki/Recursion_(computer_science)#Indirect_recursion) as "_function is called not by itself but by another function that it called (either directly or indirectly)... Indirect recursion is also called mutual recursion, which is a more symmetric term, though this is simply a difference of emphasis, not a different notion_". This is different from the book, which regards mutual recursion as a special case of indirect recursion
- The book points out that to convert a recursive function to an iterative one with an explicit stack, you should push the first recursive call onto the stack, and then set up a while loop that pops a recursive call off the stack and processes it. The processing can push new recursive calls onto the stack as necessary. The book points out that the resulting code is often not that clean. 

## 8. An Introduction to Sorting
- `Comparable<T>` is defined in the Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/lang/Comparable.html) as "_This interface imposes a total ordering on the objects of each class that implements it. This ordering is referred to as the class's natural ordering, and the class's compareTo method is referred to as its natural comparison method. Lists (and arrays) of objects that implement this interface can be sorted automatically by `Collections.sort` (and `Arrays.sort`)_"
- Lower bounded wildcards with Comparable are discussed in the Java [documentation](https://docs.oracle.com/javase/tutorial/extra/generics/morefun.html): "_It isn't necessary that T be comparable to exactly itself. All that's required is that T be comparable to one of its supertypes... This reasoning applies to almost any usage of Comparable that is intended to work for arbitrary types: You always want to use Comparable<? super T>. In general, if you have an API that only uses a type parameter T as an argument, its uses should take advantage of lower bounded wildcards (? super T). Conversely, if the API only returns T, you'll give your clients more flexibility by using upper bounded wildcards (? extends T)_"
- Selection sort is defined in [Wikipedia](https://en.wikipedia.org/wiki/Selection_sort) as "_in-place comparison sorting algorithm. It has a O(n<super>2</super>) time complexity, which makes it inefficient on large lists, and generally performs worse than the similar insertion sort.... The algorithm divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front (left) of the list and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, exchanging (swapping) it with the leftmost unsorted element (putting it in sorted order), and moving the sublist boundaries one element to the right_". It's not stable due to the swaps
- Insertion sort is defined in [Wikipedia](https://en.wikipedia.org/wiki/Insertion_sort) as "_Adaptive, i.e., efficient for data sets that are already substantially sorted: the time complexity is O(kn) when each element in the input is no more than k places away from its sorted position.... typically done in-place, by iterating up the array, growing the sorted list behind it. At each array-position, it checks the value there against the largest value in the sorted list (which happens to be next to it, in the previous array-position checked). If larger, it leaves the element in place and moves to the next. If smaller, it finds the correct position within the sorted list, shifts all the larger values up to make a space, and inserts into that correct position.... While some divide-and-conquer algorithms such as quicksort and mergesort outperform insertion sort for larger arrays, non-recursive sorting algorithms such as insertion sort or selection sort are generally faster for very small arrays (the exact size varies by environment and implementation, but is typically between 7 and 50 elements). Therefore, a useful optimization in the implementation of those algorithms is a hybrid approach, using the simpler algorithm when the array has been divided to a small size.... If a more sophisticated data structure (e.g., heap or binary tree) is used, the time required for searching and insertion can be reduced significantly; this is the essence of heap sort and binary tree sort_"
- The book points out that insertion sort on linked lists is unlike arrays, instead you make a new linked list with the head of the old linked list, then repeatedly step through the old linked list and add each node to the new linked list in the correct position
- Shellsort is defined in [Wikipedia](https://en.wikipedia.org/wiki/Shellsort) as "_can be understood as...a generalization of...sorting by insertion (insertion sort). The method starts by sorting pairs of elements far apart from each other, then progressively reducing the gap between elements to be compared. By starting with far-apart elements, it can move some out-of-place elements into the position faster than a simple nearest-neighbor exchange.... effectively finishing with an ordinary insertion sort_"

## 9. Faster Sorting Methods
- Merge sort is defined in [Wikipedia](https://en.wikipedia.org/wiki/Merge_sort) as "_Divide the unsorted list into n sub-lists, each containing one element (a list of one element is considered sorted). Repeatedly merge sublists to produce new sorted sublists until there is only one sublist remaining. This will be the sorted list_"
- Divide-and-conquer algorithm is defined in [Wikipedia](https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm) as "_recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem_"
- Bottom-up implementation is defined in [Wikipedia](https://en.wikipedia.org/wiki/Merge_sort#Bottom-up_implementation) as "_treats the list as an array of n sublists (called runs in this example) of size 1, and iteratively merges sub-lists back and forth between two buffers_"
- `java.util.Arrays.sort` for reference types is described in the Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Arrays.html#sort(java.lang.Object%5B%5D)) as "_stable, adaptive, iterative mergesort that requires far fewer than n lg(n) comparisons when the input array is partially sorted, while offering the performance of a traditional mergesort when the input array is randomly ordered. If the input array is nearly sorted, the implementation requires approximately n comparisons. Temporary storage requirements vary from a small constant for nearly sorted input arrays to n/2 object references for randomly ordered input arrays... The implementation was adapted from Tim Peters's list sort for Python (TimSort)_"
- `java.util.Arrays.parallelsort` for reference types is described in the Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Arrays.html#parallelSort(T%5B%5D)) as "_The sorting algorithm is a parallel sort-merge that breaks the array into sub-arrays that are themselves sorted and then merged. When the sub-array length reaches a minimum granularity, the sub-array is sorted using the appropriate Arrays.sort method... The algorithm requires a working space no greater than the size of the original array_"
- Stable sort algorithm is defined in [Wikipedia](https://en.wikipedia.org/wiki/Sorting_algorithm#:~:text=Stable%20sort%20algorithms%20sort%20equal,versions%20of%20the%20original%20list.) as "_sort equal elements in the same order that they appear in the input_"
- Quicksort is defined in [Wikipedia](https://en.wikipedia.org/wiki/Quicksort) as "_selecting a "pivot" element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot... The sub-arrays are then sorted recursively_"
- The book points out that elements equal to the pivot can be put in either partition because doing otherwise might tilt the partition
- The book presents a variant of the Hoare partition scheme which is defined in [Wikipedia](https://en.wikipedia.org/wiki/Quicksort#Hoare_partition_scheme) as "_uses two pointers (indices into the range) that start at both ends of the array being partitioned, then move toward each other, until they detect an inversion: a pair of elements, one greater than the pivot at the first pointer, and one less than the pivot at the second pointer; if at this point the first pointer is still before the second, these elements are in the wrong order relative to each other, and they are then exchanged. After this the pointers are moved inwards, and the search for an inversion is repeated; when eventually the pointers cross (the first points after the second), no exchange is performed; a valid partition is found, with the point of division between the crossed pointers (any entries that might be strictly between the crossed pointers are equal to the pivot and can be excluded from both sub-ranges formed)_"
- Median-of-three pivot is described in [Wikipedia](https://en.wikipedia.org/wiki/Quicksort#Choice_of_pivot) as "_choosing the median of the first, middle and last element of the partition for the pivot (as recommended by Sedgewick). This "median-of-three" rule counters the case of sorted (or reverse-sorted) input, and gives a better estimate of the optimal pivot (the true median) than selecting any single element, when no information about the ordering of the input is known_"
- `java.util.Arrays.sort` and `.parallelsort` for primitive types are described in the Java [documentation](https://docs.oracle.com/en/java/javase/24/docs/api/java.base/java/util/Arrays.html#sort(int%5B%5D)) as "_Dual-Pivot Quicksort... This algorithm offers O(n log(n)) performance on all data sets, and is typically faster than traditional (one-pivot) Quicksort implementations_"
- Radix sort is defined in [Wikipedia](https://en.wikipedia.org/wiki/Radix_sort) as "_avoids comparison by creating and distributing elements into buckets according to their radix. For elements with more than one significant digit, this bucketing process is repeated for each digit, while preserving the ordering of the prior step, until all digits have been considered_". The book presents an implemenentation with a queue for each bucket
- The book recommends insertion sort for small and almost-sorted arrays, quick sort for typical arrays, and merge sort for arrays too large to fit in memory

## 10. Queues, Dequeues & Priority Queues
- Queue is defined in [Wikipedia](https://en.wikipedia.org/wiki/Queue_(abstract_data_type)) as "_collection of entities that are maintained in a sequence and can be modified by the addition of entities at one end of the sequence and the removal of entities from the other end of the sequence_"
- Poisson distribution is defined in [Wikipedia](https://en.wikipedia.org/wiki/Poisson_distribution) as "_discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time if these events occur with a known constant mean rate and independently of the time since the last event_

- 
- Double-ended queue / deque is defined in Wikipedia as "_generalizes a queue, for which elements can be added to or removed from either the front (head) or back (tail)_"



